\documentclass{beamer}  

%\usepackage[toc,highlight,blackframe,notes,FXJ]{HA-prosper}
\usepackage[latin1]{inputenc} 
\usepackage[T1]{fontenc} 
\usepackage[francais]{babel}
\usepackage{listings}
\usepackage{graphics}
\usepackage{courier}
\usepackage{url}
\usepackage{colortbl}
%\usepackage{pstricks}
\usepackage{multicol}

\lstset{basicstyle=\tt,tabsize=2}
\newcommand{\rouge}[1]{\textcolor{red}{\textbf{\scriptsize #1}}}

%\HAPsetup{
%lf=\href{http://www.math-info.univ-paris5.fr/~jollois}{F.-X. Jollois},
%rf=Modélisation et Analyse de données,
%sn={-~\#\theframe},
%tsnav=FullScreen,
%nsnav=ShowBookmarks,
%%trans=Wipe,
%template=frame,
%stype=2,
%sstart=1,
%iacolor=lightgray
%}

\title{Modélisation et Analyse de données}
\author{F.-X. Jollois}
%\date{}


\begin{document} 

\maketitle
%
%%--------------------------------------------------------------------- frame
%\begin{frame}{}
%\end{frame}
%%--------------------------------------------------------------------- 


%--------------------------------------------------------------------- frame
\begin{frame}{Plan}
\begin{itemize}
	\item Modélisation
		\begin{itemize}
			\item Modèle linéaire
			\item Modèle linéaire général
			\item Régression logistique
		\end{itemize}
	\item[]
	\item Arbres de décision
		\begin{itemize}
			\item Classification et Régression
		\end{itemize}
	\item[]
	\item Quelle méthode ? Quelle modèle ?
		\begin{itemize}
			\item Comparaison de modèles/méthodes
			\item Apprentissage
		\end{itemize}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}{Introduction}
\begin{itemize}
	\item Modèle linéaire
		\begin{itemize}
			\item Régression multiple
		\end{itemize}
	\item[]
	\item Modèle linéaire général
		\begin{itemize}
			\item Limites du modèle linéaire
			\item Solution adoptée
		\end{itemize}
	\item[]
	\item Régression logistique
		\begin{itemize}
			\item Pourquoi ?
		\end{itemize}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Régression linéraire}
\begin{frame}
  \tableofcontents[currentsection]
\end{frame}      

%--------------------------------------------------------------------- SLIDE
\begin{frame}{But de la régression}
\begin{itemize}
	\item Corrélation : liaison \emph{symétrique} entre deux variables
	\item[]
	\item Rôle pas forcément symétrique (entre taille et poids, par exemple)
	\item[]
	\item Poids : variable \textbf{dépendante} (dénommée souvent $Y$)
	\item Âge : variable \textbf{explicative} (dénommée souvent $X$)
	\item Le poids est fonction de l'âge (et non l'inverse)
	\item[]
	\item Quelle est la relation de dépendance de $Y$ par rapport à $X$ ?
	\item Recherche d'une \textbf{régression} de $Y$ en fonction de $X$
\end{itemize}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple}
	\centerline{\includegraphics[scale=0.35]{mtcars_disp_wt_lm.pdf}}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}{Description}
\begin{itemize}
	\item Trois fonctions essentielles de la régression
		\begin{itemize}
			\item Décrire la façon dont $Y$ est liée à $X$
			\item Tester l'existence de cette liaison
			\item Estimer une valeur de $Y$ pour une valeur de $X$ donnée
		\end{itemize}
	\item[]
	\item Obtenir les valeurs de l'équation $Y = bX + a$
		\begin{itemize}
			\item $b$ : pente de la droite
			\item $a$ : ordonnée à l'origine
		\end{itemize}
	\item[]
	\item Minimisation de la somme des carrés des distances entre les points et la droite
\end{itemize}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}{Calcul et test}
\begin{itemize}
	\item \emph{Droite des moindres carrés} appelée aussi droite de régression
	\item[]
	\item Pente $b$ fournie par le rapport $\frac{cov(XY)}{var(X)} = \frac{\sum xy}{\sum x^2}$
	\item Coordonnée à l'origine $a$ obtenue avec $\mu_y - b \hat \mu_x X$
	\item Passe par le point ($\mu_x$, $\mu_y$) (point moyen)
	\item[]
	\item Si $X$ et $Y$ non liée, droite horizontale avec pente nulle ($b = 0$)
	\item[]
	\item Sous $H_0$, le rapport $\frac{|b - 0|}{\sigma_b}$ suit une loi $T$ de Student ($ddl = n-2$)
	\item[]
	\item Test de nullité de la pente $b$ et de $R^2$	
	\item[]
	\item Estimation d'une valeur de $Y$ obtenue grâce à la formule $bx + a$ (avec un intervalle de confiance)
\end{itemize}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple}
\begin{itemize}
	\item Création de trois modèles
\begin{lstlisting}
m1 = lm(german$V2 ~ german$V5)
m2 = lm(german$V2 ~ german$V8)
m3 = lm(german$V2 ~ german$V13)
\end{lstlisting}
	\item[]
	\item Analyse de ces trois modèles
\begin{lstlisting}
summary(m1)
summary(m2)
summary(m3)
\end{lstlisting}
	\item[]
	\item Résumé
		\begin{center}
		\begin{tabular}{llccc}
		Modèle & Variable & $b$ & $p$ & $R^2$\\
		\hline
		\lstinline!m1! & \lstinline!V5!  &  0.0027 & <2e-16 & 0.39\\
		\lstinline!m2! & \lstinline!V8!  &  0.8057 & 0.018  & 0.0046\\
		\lstinline!m3! & \lstinline!V13! & -0.0383 & 0.254  & 0.0003\\
		\end{tabular}
		\end{center}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple}
\begin{center}
\includegraphics[scale=0.35]{german_lm_V2_V5V8V13.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Analyse des résidus}
\begin{center}
\includegraphics[scale=0.35]{german_lm_V2_V5_plot.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- SLIDE
\begin{frame}{Avec plus de deux variables}
\begin{itemize}
	\item Obtenir la fonction $f$ tel que $Y = f(X_1, X_2, X_3, \ldots, X_p)$
	\item[]
	\item Plusieurs variables \emph{explicatives}
	\item[]
	\item Exemple avec $p=2$ : $Y = b_0 + b_1 X_1 + b_2 X_2$
	\item[]
	\item Recherche de l'hyper-plan minimisant la distance entre les points et celui-ci
	\item[]
	\item \'Evaluer la force de la liaison entre $Y$ et chacun des $X_i$
	\item[]
	\item \'Etablir une \emph{hiérarchie} entre ces différentes liaisons
\end{itemize}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}{Régression multiple}
\begin{itemize}
	\item Utilisation de la régression multiple
		\begin{itemize}
			\item \'Eliminer le biais éventuellement créé par d'autre variables
			\item Améliorer l'estimation de nouvelles valeurs en réduisant les intervalles de confiance
		\end{itemize}
	\item[]
	\item Ajustement au sens des moindres carrés
	\item[]
	\item Test de nullité du coefficient pour chaque variable explicative
	\item[]
	\item Test de nullité du coefficient de corrélation globale $R^2$
\end{itemize}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple}
\begin{itemize}
	\item Création des différents modèles
\begin{lstlisting}
m4 = lm(V2 ~ V5 + V8, data = german)
m5 = lm(V2 ~ V5 + V13, data = german)
m6 = lm(V2 ~ V8 + V13, data = german)
m7 = lm(V2 ~ V5 + V8 + V13, data = german)
\end{lstlisting}
	\item[]
	\item Informations obtenues avec \lstinline!summary!
\begin{lstlisting}
summary(m4)
summary(m5)
summary(m6)
summary(m7)
\end{lstlisting}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple}
\begin{itemize}
	\item Résumé
		\begin{center}
		\begin{tabular}{llccc}
		Modèle & Variables & $b$ & $p$ & $R^2$\\
		\hline
		\lstinline!m4! & \lstinline!V5!  &  0.0030 & <2e-16 & 0.4539\\
		         & \lstinline!V8!  &  2.8428 & <2e-16 & \\
		\hline
		\lstinline!m5! & \lstinline!V5!  &  0.0027 & <2e-16 & 0.3926\\
		         & \lstinline!V13! & -0.0600 & 0.0219 & \\
		\hline
		\lstinline!m6! & \lstinline!V8!  &  0.8312 & 0.0149 & 0.0052\\
		         & \lstinline!V13! & -0.0431 & 0.1990 & \\
		\hline
		\lstinline!m7! & \lstinline!V5!  &  0.0030 & <2e-16 & 0.459\\
		         & \lstinline!V8!  &  2.9012 & <2e-16 & \\
		         & \lstinline!V13! & -0.0792 & 0.0014 & \\
		\end{tabular}
		\end{center}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}{Suppression de facteurs}
\begin{itemize}
	\item Importance des facteurs différents
	\item[]
	\item Si coefficient $b_i$ considéré comme nul, enlever $X_i$
	\item[]
	\item Faire aussi intervenir la connaissance métier
	\item[]
	\item Ommission de variables exogènes entrainant du biais
		\begin{itemize}
			\item Tirage aléatoire
		\end{itemize}
	\item[]
	\item Exemple avec suppression des variables avec un coefficient $b_i$ nul
\end{itemize}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple de suppression de facteurs}
\small
\begin{lstlisting}
lm(V2 ~ V5 + V8 + V11 + V13 + V16 + V18, data=german)   

Adjusted R-squared: 0.4583

              Estimate Std. Error t value Pr(>|t|)    
(Intercept)  5.5781436  1.6518262   3.377 0.000761 ***
V5           0.0029909  0.0001036  28.880  < 2e-16 ***
V8           2.8893754  0.2625455  11.005  < 2e-16 ***
V11          0.2544524  0.2646117   0.962 0.336481    
V13         -0.0815216  0.0260134  -3.134 0.001776 ** 
V16         -0.4502932  0.4946258  -0.910 0.362848    
V18         -0.2093616  0.7870663  -0.266 0.790293    
\end{lstlisting}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple de suppression de facteurs}
\small
\begin{lstlisting}
lm(V2 ~ V5 + V8 + V11 + V13 + V16, data=german)         

Adjusted R-squared: 0.4588
 
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)  5.3633764  1.4403865   3.724 0.000207 ***
V5           0.0029912  0.0001035  28.898  < 2e-16 ***
V8           2.8949991  0.2615705  11.068  < 2e-16 ***
V11          0.2537538  0.2644749   0.959 0.337559    
V13         -0.0822315  0.0258640  -3.179 0.001522 ** 
V16         -0.4627451  0.4921755  -0.940 0.347342    
\end{lstlisting}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple de suppression de facteurs}
\small
\begin{lstlisting}
lm(V2 ~ V5 + V8 + V11 + V13, data = german)        
     
Adjusted R-squared: 0.4589 

              Estimate Std. Error t value Pr(>|t|)    
(Intercept)  4.8779481  1.3445949   3.628 0.000300 ***
V5           0.0029894  0.0001035  28.887  < 2e-16 ***
V8           2.8910451  0.2615215  11.055  < 2e-16 ***
V11          0.2410033  0.2641116   0.913 0.361724    
V13         -0.0853715  0.0256460  -3.329 0.000904 ***
\end{lstlisting}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple de suppression de facteurs}
\small
\begin{lstlisting}
lm(V2 ~ V5 + V8 + V13, data=german)                 
    
Adjusted R-squared: 0.459

              Estimate Std. Error t value Pr(>|t|)    
(Intercept)  5.3051161  1.2603675   4.209 2.79e-05 ***
V5           0.0029924  0.0001034  28.933  < 2e-16 ***
V8           2.9011833  0.2612634  11.104  < 2e-16 ***
V13         -0.0792242  0.0247433  -3.202  0.00141 ** 
\end{lstlisting}
\normalsize
\begin{itemize}
	\item Modèle \emph{optimal}	
		\begin{itemize}
			\item $R^2$ ajusté très proche (voire supérieur) par rapport au modèle complet
			\item Toutes les variables ont un effet significatif
		\end{itemize}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- SLIDE
\begin{frame}{Choix du \emph{bon} modèle}
\begin{itemize}
	\item Obtenir le modèle le plus proche de la réalité
		\begin{itemize}
			\item $R^2$ le plus proche de 1 possible
			\item Simple à interpréter (pas trop de variables)
		\end{itemize}
	\item[]
	\item Critère de choix du modèle ($AIC$ par exemple)
	$$ AIC(m) = -2L(m) + 2 \nu(m) $$
	\item[]
	\item Plusieurs possibilités pour optimiser le critère à chaque étape
		\begin{itemize}
			\item \textbf{Entrée} (ou \emph{forward}) : ajout de variable
			\item \textbf{Sortie} (ou \emph{backward}) : suppression de variable
			\item \textbf{Pas à pas} (ou \emph{stepwise}) : ajout et suppression de variables jusqu'à stabilisation
		\end{itemize}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple 1 : \lstinline!Life Cycle Savings!}
\begin{itemize}
	\item Création du modèle complet
\begin{lstlisting}
pairs(LifeCycleSavings, panel = panel.smooth, 
  main = "LifeCycleSavings data")
m = lm(sr ~ pop15 + pop75 + dpi + ddpi, 
  data = LifeCycleSavings)
summary(m)
\end{lstlisting}
	\item[]
	\item Choix des variables à garder selon le critère
\begin{lstlisting}
step(m, dir = "forward")
step(m, dir = "backward")
step(m, dir = "both")
\end{lstlisting}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple 2 : \lstinline!Swiss!}
\begin{itemize}
	\item Création du modèle complet
\begin{lstlisting}
pairs(swiss, panel = panel.smooth, 
  main = "swiss data", 
  col = 3 + (swiss$Catholic > 50))
summary(m <- lm(Fertility ~ . , data = swiss))
\end{lstlisting}
	\item[]
	\item Choix des variables à garder selon le critère
\begin{lstlisting}
step(m, dir = "forward")
step(m, dir = "backward")
step(m, dir = "both")
\end{lstlisting}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple 3 : \lstinline!Attitude!}
\begin{itemize}
	\item Création du modèle complet
\begin{lstlisting}
pairs(attitude, main = "attitude data")
summary(attitude)
summary(m <- lm(rating ~ ., data = attitude))
\end{lstlisting}
	\item[]
	\item Choix des variables à garder selon le critère
\begin{lstlisting}
step(m, dir = "forward")
step(m, dir = "backward")
step(m, dir = "both")
\end{lstlisting}
\end{itemize}
\end{frame}
%---------------------------------------------------------------------

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple 3 : \lstinline!Attitude!}
\small
\begin{lstlisting}
lm(formula = rating ~ ., data = attitude)

Multiple R-squared: 0.7326,     Adjusted R-squared: 0.6628 

            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 10.78708   11.58926   0.931 0.361634    
complaints   0.61319    0.16098   3.809 0.000903 ***
privileges  -0.07305    0.13572  -0.538 0.595594    
learning     0.32033    0.16852   1.901 0.069925 .  
raises       0.08173    0.22148   0.369 0.715480    
critical     0.03838    0.14700   0.261 0.796334    
advance     -0.21706    0.17821  -1.218 0.235577    

\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple 3 : \lstinline!Attitude!}
\begin{center}
\includegraphics[scale=0.35]{attitude_lm_rating_all.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple 3 : \lstinline!Attitude!}
\small
\begin{lstlisting}
Start:  AIC=123.36
rating ~ complaints + privileges + learning + raises + critical + 
    advance

             Df Sum of Sq     RSS     AIC
- critical    1      3.41 1152.41  121.45
- raises      1      6.80 1155.80  121.54
- privileges  1     14.47 1163.47  121.74
- advance     1     74.11 1223.11  123.24
<none>                    1149.00  123.36
- learning    1    180.50 1329.51  125.74
- complaints  1    724.80 1873.80  136.04
\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple 3 : \lstinline!Attitude!}
\small
\begin{lstlisting}
Step:  AIC=121.45
rating ~ complaints + privileges + learning + raises + advance

             Df Sum of Sq     RSS     AIC
- raises      1     10.61 1163.01  119.73
- privileges  1     14.16 1166.57  119.82
- advance     1     71.27 1223.67  121.25
<none>                    1152.41  121.45
+ critical    1      3.41 1149.00  123.36
- learning    1    177.74 1330.14  123.76
- complaints  1    724.70 1877.11  134.09
\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple 3 : \lstinline!Attitude!}
\small
\begin{lstlisting}
Step:  AIC=119.73
rating ~ complaints + privileges + learning + advance

             Df Sum of Sq     RSS     AIC
- privileges  1     16.10 1179.11  118.14
- advance     1     61.60 1224.62  119.28
<none>                    1163.01  119.73
+ raises      1     10.61 1152.41  121.45
+ critical    1      7.21 1155.80  121.54
- learning    1    197.03 1360.05  122.42
- complaints  1   1165.94 2328.95  138.56
\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple 3 : \lstinline!Attitude!}
\small
\begin{lstlisting}
Step:  AIC=118.14
rating ~ complaints + learning + advance

             Df Sum of Sq     RSS     AIC
- advance     1     75.54 1254.65  118.00
<none>                    1179.11  118.14
+ privileges  1     16.10 1163.01  119.73
+ raises      1     12.54 1166.57  119.82
+ critical    1      7.18 1171.93  119.96
- learning    1    186.12 1365.23  120.54
- complaints  1   1259.91 2439.02  137.94
\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple 3 : \lstinline!Attitude!}
\small
\begin{lstlisting}
Step:  AIC=118
rating ~ complaints + learning

             Df Sum of Sq     RSS     AIC
<none>                    1254.65  118.00
+ advance     1     75.54 1179.11  118.14
- learning    1    114.73 1369.38  118.63
+ privileges  1     30.03 1224.62  119.28
+ raises      1      1.19 1253.46  119.97
+ critical    1  0.002134 1254.65  120.00
- complaints  1   1370.91 2625.56  138.16
\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple 3 : \lstinline!Attitude!}
\small
\begin{lstlisting}
lm(formula = rating ~ complaints + learning, data = attitude)

Multiple R-squared: 0.708,      Adjusted R-squared: 0.6864 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   9.8709     7.0612   1.398    0.174    
complaints    0.6435     0.1185   5.432 9.57e-06 ***
learning      0.2112     0.1344   1.571    0.128    
\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple 3 : \lstinline!Attitude!}
\begin{center}
\includegraphics[scale=0.35]{attitude_lm_rating_both.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- SLIDE
\begin{frame}[fragile]{Exemple 3 : \lstinline!Attitude!}
\small
\begin{lstlisting}
Call:
lm(formula = rating ~ complaints, data = attitude)

Multiple R-squared: 0.6813,     Adjusted R-squared: 0.6699 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 14.37632    6.61999   2.172   0.0385 *  
complaints   0.75461    0.09753   7.737 1.99e-08 ***
\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 


%--------------------------------------------------------------------- frame
\begin{frame}{Modèle linéaire}
\begin{itemize}
	\item Régression multiple
	\item[]
	\item Interprétation des coefficients $b_i$
		\begin{itemize}
			\item Variation de $Y$ = $b_i$ $\times$ Variation de $X_i$
			\item \emph{Toute chose étant égale par ailleurs}
		\end{itemize}
	\item[]
	\item Colinéarité
		\begin{itemize}
			\item Est-ce un problème ?
		\end{itemize}
	\item[]
	\item Interaction
		\begin{itemize}
			\item Exemple
		\end{itemize}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple sur la colinéarité}
\begin{itemize}
	\item Corrélation entre variables et modèle complet
\end{itemize}
\small
\begin{lstlisting}
           rating complaints raises
rating       1.00       0.83   0.59
complaints   0.83       1.00   0.67
raises       0.59       0.67   1.00

lm(formula = raises ~ rating + complaints, data = attitude)
Multiple R-squared: 0.4523,     Adjusted R-squared: 0.4117 
            Estimate Std. Error t value Pr(>|t|)   
(Intercept)  28.3752     8.1598   3.477  0.00173 **
rating        0.1012     0.2155   0.470  0.64228   
complaints    0.4462     0.1970   2.265  0.03177 * 
\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile] {Exemple sur la colinéarité}
\begin{itemize}
	\item Modèles restreints
\end{itemize}
\small
\begin{lstlisting}
lm(formula = raises ~ complaints, data = attitude)
Multiple R-squared: 0.4478,     Adjusted R-squared: 0.4281 
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  29.8306     7.4430   4.008 0.000411 ***
complaints    0.5226     0.1097   4.765 5.27e-05 ***

lm(formula = raises ~ rating, data = attitude)
Multiple R-squared: 0.3483,     Adjusted R-squared: 0.325 
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  32.0537     8.5658   3.742 0.000835 ***
rating        0.5041     0.1303   3.868 0.000598 ***
\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile] {Interaction -- Exemple}
\begin{itemize}
	\item Et si deux variables explicatives interagissent ?
\end{itemize}
\small
\begin{lstlisting}
lm(formula = V2 ~ V5 + V13, data = german)
Multiple R-squared: 0.3938,     Adjusted R-squared: 0.3926 
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) 14.2774337  1.0249180  13.930   <2e-16 ***
V5           0.0026779  0.0001054  25.408   <2e-16 ***
V13         -0.0600470  0.0261532  -2.296   0.0219 *  

lm(formula = V2 ~ V5 * V13, data = german)
Multiple R-squared: 0.3965,     Adjusted R-squared: 0.3947 
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.215e+01  1.440e+00   8.439   <2e-16 ***
V5           3.339e-03  3.322e-04  10.050   <2e-16 ***
V13         -1.843e-03  3.809e-02  -0.048   0.9614    
V5:V13      -1.795e-05  8.556e-06  -2.098   0.0361 *  
\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Interaction -- Exemple}
\begin{center}
\includegraphics[scale=0.35]{german_V2_V5V13_lm_int.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}{Modèle linéaire général}
\begin{itemize}
	\item Limitations du modèle linéaire
		\begin{itemize}
			\item Non prise en compte de variables qualitatives
			\item Possibilité si ordinale = considérée comme quantitative, mais \ldots
		\end{itemize}
	\item[]
	\item Solution adoptée
		\begin{itemize}
			\item Introduction de variables muettes (0-1)
			\item Prise en compte dans le calcul
			\item Pour $X_i=1$, variation de $b_i$
		\end{itemize}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}{Variable muette}
\begin{itemize}
	\item Variable muette $D$ = variable binaire (prenant la valeur 0 ou 1)
	\item[]
	\item \'Equation de la droite de régression inchangée
		$$ Y = b_0 + b_1 X + b_2 D $$
	\item[]
	\item Variation lorsque $D=1$ de $b_2$
		\begin{itemize}
			\item Les valeurs de $Y$ pour les objets pour lesquels $D=1$ sont globalement différente d'un niveau $b_2$ par rapport à celles des objets pour lesquels $D=0$
			\item Deux droites de régression (parallèles)
		\end{itemize}
	\item[]
	\item Pour le groupe $D=0$ : $Y = b_0 + b_1 X$
	\item Pour le groupe $D=1$ : $Y = (b_0 + b_2) + b_1 X$
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple de variable muette}
\small
\begin{lstlisting}
lm(formula = y ~ x)
Multiple R-squared: 0.7365,     Adjusted R-squared: 0.7338 
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.45998    0.07177  -6.409 5.13e-09 ***
x            1.94994    0.11781  16.552  < 2e-16 ***
\end{lstlisting}
\begin{center}
\includegraphics[scale=0.2,angle=90]{muette1.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple de variable muette}
\small
\begin{lstlisting}
lm(formula = y ~ x + d)
Multiple R-squared: 0.9188,     Adjusted R-squared: 0.9171 
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.008772   0.051125   0.172    0.864    
x            1.921048   0.065779  29.205   <2e-16 ***
d           -0.381070   0.025831 -14.752   <2e-16 ***
\end{lstlisting}
\begin{center}
\includegraphics[scale=0.2,angle=90]{muette2.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}{Variable muette à plusieurs catégories}
\begin{itemize}
	\item Binaire : traitement vs absence de traitement
	\item Ternaire : traitement 1, traitement 2 et absence de traitement
	\item[]
	\item Créer deux variables muettes $D_A$ et $D_B$
		\begin{itemize}
			\item $D_A=1$ si Traitement 1 et $D_A=0$ sinon
			\item $D_B=1$ si Traitement 2 et $D_B=0$ sinon
		\end{itemize}
	\item[]
	\item Codage disjonctif partiel
	\item \'Equation : $Y = b_0 + b_1 X + b_2 D_A + b_3 D_B $
	\item[]
	\item Pour le groupe $D=0$ : $Y = b_0 + b_1 X$
	\item Pour le groupe $D=1$ : $Y = (b_0 + b_2) + b_1 X$
	\item Pour le groupe $D=2$ : $Y = (b_0 + b_3) + b_1 X$
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple de variable muette à 3 modalités}
\small
\begin{lstlisting}
lm(formula = y ~ x)
Multiple R-squared: 0.7572,     Adjusted R-squared: 0.7547 
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.49056    0.07088  -6.921 4.67e-10 ***
x            2.06611    0.11818  17.483  < 2e-16 ***
\end{lstlisting}
\begin{center}
\includegraphics[scale=0.2,angle=90]{muette3.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple de variable muette à 3 modalités}
\small
\begin{lstlisting}
lm(formula = y ~ x + d1 + d2)
Multiple R-squared: 0.9191,     Adjusted R-squared: 0.9166 
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.04236    0.05261  -0.805    0.423    
x            2.02572    0.06902  29.350  < 2e-16 ***
d1          -0.55582    0.05774  -9.627 9.42e-16 ***
d2          -0.66832    0.04973 -13.439  < 2e-16 ***
\end{lstlisting}
\begin{center}
\includegraphics[scale=0.2,angle=90]{muette4.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}{Pentes différentes}
\begin{itemize}
	\item Extension au cas de droites avec des pentes différentes
	\item[]
	\item Variable muette pas suffisante (droites non parallèles)
	\item[]
	\item Introduction de la variable $D \times X$ (interaction)
	\item[]
	\item \'Equation de la droite de régression
		$$ Y = b_0 + b_1 X + b_2 D + b_3 D X $$
	\item[]
	\item Pour le groupe $D=0$ : $Y = b_0 + b_1 X$
	\item Pour le groupe $D=1$ : $Y = (b_0 + b_2) + (b_1 + b_3) X$
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple avec pentes différentes}
\small
\begin{lstlisting}
lm(formula = y ~ x)
Multiple R-squared: 0.07725,    Adjusted R-squared: 0.06784 
            Estimate Std. Error t value Pr(>|t|)   
(Intercept)   0.1140     0.1379   0.827  0.41023   
x             0.7017     0.2450   2.864  0.00511 **
\end{lstlisting}
\begin{center}
\includegraphics[scale=0.2,angle=90]{muette5.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple avec pentes différentes}
\small
\begin{lstlisting}
lm(formula = y ~ x + d + d:x)
Multiple R-squared: 0.9422,     Adjusted R-squared: 0.9404 
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.01468    0.04906  -0.299    0.765    
x            2.03191    0.08613  23.591  < 2e-16 ***
d            0.33848    0.06974   4.853  4.7e-06 ***
x:d         -2.80308    0.12393 -22.619  < 2e-16 ***
\end{lstlisting}
\begin{center}
\includegraphics[scale=0.2,angle=90]{muette6.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple d'application}
\small
\begin{lstlisting}
lm(formula = V2 ~ V5 * V12 + V20 + V13, data = german)
Multiple R-squared: 0.4243,     Adjusted R-squared: 0.4191 
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) 11.1900475  1.3275728   8.429  < 2e-16 ***
V5           0.0036172  0.0003419  10.579  < 2e-16 ***
V12A122      3.3877586  1.3184704   2.569 0.010331 *  
V12A123      5.1426756  1.2277196   4.189 3.05e-05 ***
V12A124      7.5809787  1.5395562   4.924 9.92e-07 ***
V20A202     -5.7513530  1.5614000  -3.683 0.000243 ***
V13         -0.0652582  0.0262795  -2.483 0.013184 *  
V5:V12A122  -0.0011495  0.0004143  -2.775 0.005629 ** 
V5:V12A123  -0.0011456  0.0003842  -2.981 0.002939 ** 
V5:V12A124  -0.0014009  0.0003958  -3.540 0.000419 ***
\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}{Non-linéarité et logarithmes}
\begin{itemize}
	\item Pourquoi ?
		\begin{itemize}
			\item Modèle linéaire valable si linéarité en $b$
		\end{itemize}
	\item[]
	\item Modèle multiplicatif
	\item[]
	\item Exemple de modèle
		$$ Y = b_0 {X_1}^{b_1} {X_2}^{b_2}$$
	\item[]
	\item Transformation de l'équation pour la rendre linéaire en $b$
		$$ log(Y) = log(b_0) + b_1 log(X_1) + b_2 log(X_2) $$
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Régression logistique}
\begin{frame}
  \tableofcontents[currentsection]
\end{frame}      

%--------------------------------------------------------------------- frame
\begin{frame}{Régression logistique}
\begin{itemize}
	\item Pourquoi ?
		\begin{itemize}
			\item Adaptation aux variables expliquées qualitatives
		\end{itemize}
	\item[]
	\item Cas d'une variable binaire $Y$
	\item[]
	\item Recherche de la probabilité $\pi$ que $Y=1$ (comprise entre 0 et 1)
	\item[]
	\item Modèle linéaire inutilisable dans un tel cas
	\item[]
	\item Transformation la plus utilisée : fonction logit
		$$ logit(\pi) = log \left( \frac{\pi}{1-\pi} \right) = b_0 + b_1 X_1 + \ldots + b_p X_p $$
	  $$ \pi(X_1,\ldots,X_p) = \frac{exp(b_0 + b_1 X_1 + \ldots + b_p X_p)}{1 + exp(b_0 + b_1 X_1 + \ldots + b_p X_p)}$$
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}{Régression logistique}
\begin{center}
\includegraphics[scale=0.35,angle=90]{reglog.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}{Régression logistique}
\begin{itemize}
	\item Alors que $logit(\pi)$ peut prendre n'importe quelle valeur, $\pi \in [0,1]$ toujours
	\item[]
	\item A partir du coefficient $b_i$, calcul de l'odd-ratio $exp(b_i)$
		\begin{itemize}
			\item Odd-ratio : \emph{chance} que $Y$ prenne la valeur 1 lorsque $X_i$ augmente de 1
			\item \emph{Toute chose étant égale par ailleurs}
		\end{itemize}
	\item[]
	\item Estimation par le maximum de vraisemblance
		$$ L = \prod_j P(Y(j) = 1 / X(j))^{Y(j)} \times (1 - P(Y(j) = 1 / X(j)))^{1 - Y(j)} $$
	\item[]
	\item Affectation de la valeur 1 si $P(Y/X) > 0.5$
	\item Modulation possible en fonction des probabilités a priori des modalités
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}{Apprentissage supervisé}
\begin{itemize}
	\item Cadre globale, dans lequel se place la régression (entre autres)
	\item[]
	\item Plusieurs exemples
	\item Apprendre les règles d'estimation de la valeur d'une variable (qualitative ou quantitative)
	\item \emph{Professeur} indiquant les erreurs
	\item[]
	\item But : élargir ces règles sur de nouvelles données
	\item Ne pas apprendre par c\oe ur
	\item Vérification des résultats sur d'autres données
	\item[]
	\item Variables quantitatives : erreurs ($R^2$)
	\item Variables qualitatives : matrice de confusion (taux d'erreur)
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple de régression logistique}
\begin{itemize}
	\item Niveau de salaire (plus ou moins de 50K\$) en fonction du nombre d'heures par semaine
\end{itemize}
\small
\begin{lstlisting}
glm(formula = class ~ hours_per_wk, family = binomial(), data = adult)

AIC: 51164

                 Estimate Std. Error z value Pr(>|z|)    
(Intercept)  -3.0821209  0.0429865  -71.70   <2e-16 ***
hours_per_wk  0.0458377  0.0009623   47.63   <2e-16 ***

Matrice de confusion (avec P(Y/X) > 0.5)
         less  more
  FALSE 36356 11258
  TRUE    799   429
\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}{Exemple de régression logistique}
\begin{center}
\includegraphics[scale=0.4]{adult_class_hours_glm.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}{Sensibilité / Spécificité}
\begin{itemize}
	\item Ajustement des prédictions
\begin{center}
\begin{tabular}{llp{1.5cm}p{1.5cm}}
 & & \multicolumn{2}{c}{Observé}\\
 & & \multicolumn{1}{c}{0} & \multicolumn{1}{c}{1}\\
\hline
Prédit & 0 & \multicolumn{1}{c}{a} & \multicolumn{1}{c}{b}\\
       & 1 & \multicolumn{1}{c}{c} & \multicolumn{1}{c}{d}\\
\hline
\end{tabular}
\end{center}
	\item[]
	\item Sensibilité
		\begin{itemize}
			\item Pourcentage de 1 correctement prédit par rapport à tous les 1
			\item $Sensibilite = \frac{d}{b+d}$ 
		\end{itemize}
	\item[]
	\item Sensibilité
		\begin{itemize}
			\item Pourcentage de 0 correctement prédit par rapport à tous les 0
			\item $Specificite = \frac{a}{a+c}$
		\end{itemize}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Sensibilité / Spécificité}
\small
\begin{lstlisting}
        Correct Sensibilité Spécificité
p = 0      0.24        1.00        0.00
p = 0.1    0.28        0.98        0.06
p = 0.2    0.42        0.92        0.26
p = 0.3    0.73        0.35        0.85
p = 0.4    0.75        0.13        0.94
p = 0.5    0.75        0.04        0.98
p = 0.6    0.76        0.02        0.99
p = 0.7    0.76        0.01        1.00
p = 0.8    0.76        0.00        1.00
p = 0.9    0.76        0.00        1.00
p = 1      0.76        0.00        1.00
\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple avec modèle complet}\tiny
\tiny
\begin{lstlisting}
glm(formula = class ~ ., family = binomial(), data = adult)
AIC: 31508
                                      Estimate Std. Error z value Pr(>|z|)    
(Intercept)                         -9.559e+00  3.123e-01 -30.603  < 2e-16 ***
age                                  2.233e-02  1.279e-03  17.460  < 2e-16 ***
fnlwgt                               6.562e-07  1.369e-07   4.794 1.64e-06 ***
education_num                        2.990e-01  7.166e-03  41.725  < 2e-16 ***
marital_statusMarried-AF-spouse      2.323e+00  4.547e-01   5.108 3.25e-07 ***
marital_statusMarried-civ-spouse     2.263e+00  2.132e-01  10.617  < 2e-16 ***
marital_statusMarried-spouse-absent  7.531e-02  1.766e-01   0.426 0.669826    
marital_statusNever-married         -4.277e-01  7.100e-02  -6.024 1.70e-09 ***
marital_statusSeparated             -6.123e-02  1.321e-01  -0.464 0.642978    
marital_statusWidowed                4.408e-02  1.246e-01   0.354 0.723462    
occupationArmed-Forces               9.723e-01  7.804e-01   1.246 0.212816    
occupationCraft-repair              -2.601e-02  6.321e-02  -0.411 0.680766    
occupationExec-managerial            6.615e-01  6.070e-02  10.897  < 2e-16 ***
occupationFarming-fishing           -1.315e+00  1.115e-01 -11.790  < 2e-16 ***
occupationHandlers-cleaners         -7.137e-01  1.127e-01  -6.331 2.43e-10 ***
occupationMachine-op-inspct         -3.471e-01  8.118e-02  -4.276 1.90e-05 ***
occupationOther-service             -9.799e-01  9.513e-02 -10.300  < 2e-16 ***
occupationPriv-house-serv           -2.006e+00  7.472e-01  -2.685 0.007245 ** 
occupationProf-specialty             1.832e-01  5.977e-02   3.065 0.002180 ** 
occupationProtective-serv            3.387e-01  9.781e-02   3.463 0.000535 ***
occupationSales                      1.440e-01  6.464e-02   2.228 0.025872 *  
occupationTech-support               4.921e-01  8.864e-02   5.551 2.83e-08 ***
occupationTransport-moving          -1.692e-01  7.915e-02  -2.138 0.032490 *  
relationshipNot-in-family            5.292e-01  2.110e-01   2.508 0.012142 *  
relationshipOther-relative          -5.874e-01  1.968e-01  -2.986 0.002831 ** 
relationshipOwn-child               -6.421e-01  2.074e-01  -3.096 0.001963 ** 
relationshipUnmarried                3.391e-01  2.248e-01   1.509 0.131395    
relationshipWife                     1.063e+00  8.189e-02  12.982  < 2e-16 ***
raceAsian-Pac-Islander               4.256e-01  1.938e-01   2.196 0.028060 *  
raceBlack                            2.819e-01  1.862e-01   1.514 0.129926    
raceOther                            2.323e-01  2.636e-01   0.881 0.378201    
raceWhite                            5.105e-01  1.769e-01   2.885 0.003915 ** 
sexMale                              6.868e-01  6.319e-02  10.869  < 2e-16 ***
capital_gain                         3.166e-04  8.347e-06  37.925  < 2e-16 ***
capital_loss                         6.481e-04  2.993e-05  21.655  < 2e-16 ***
hours_per_week                       3.089e-02  1.266e-03  24.399  < 2e-16 ***
\end{lstlisting}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple avec modèle complet}
\begin{itemize}
	\item Matrice de confusion
\begin{lstlisting}
         less  more
  FALSE 34574  4745
  TRUE   2581  6942
\end{lstlisting}
	\item[]
	\item Ajustement du modèle
\begin{lstlisting}
Null Deviance:      53750 
Residual Deviance:  31440        
AIC:                31510 
\end{lstlisting}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}{Représentations graphiques}
\begin{itemize}
	\item ROC
	\item[]
	\item Precision/Recall
	\item[]
	\item Sensitivity/Specificity
	\item[]
	\item Lift
	\item[]
	\item \emph{Performance}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Courbe ROC}
\begin{itemize}
	\item Taux de vrai positif vs Taux de faux positif
\end{itemize}
\includegraphics[scale=0.35]{adult_glm_ROC.pdf}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Courbe Precision/Recall}
\begin{itemize}
	\item Précision (Nb de vrai positifs sur Nb positifs prédits) vs Taux de vrai positif
\end{itemize}
\includegraphics[scale=0.35]{adult_glm_PrecRec.pdf}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Courbe Sensitivity / Specificity}
\begin{itemize}
	\item Sensibilité vs Spécificité
	\item Taux de vrai positif vs Taux de vrai négatif
\end{itemize}
\includegraphics[scale=0.35]{adult_glm_SensSpec.pdf}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Courbe Lift}
\begin{itemize}
	\item Lift (Taux de vrai positifs sur Taux de prédictions positives) vs Taux de prédictions positives
\end{itemize}
\includegraphics[scale=0.35]{adult_glm_Lift.pdf}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Courbe de \emph{performance}}
\begin{itemize}
	\item Taux de vrai positifs vs Taux de prédictions positives
	\item Pour 40 \% des positifs prédits, on 89 \% des positifs
\end{itemize}
\includegraphics[scale=0.35]{adult_glm_Perf.pdf}
\end{frame}
%--------------------------------------------------------------------- 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Arbres de décision}
\begin{frame}
  \tableofcontents[currentsection]
\end{frame}      

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Arbres de décision}
\begin{itemize}
	\item Arbres de décision
	\item[]
	\item Exemple d'arbre
	\item[]
	\item Construction de l'arbre
	\item[]
	\item Idée générale
	\item[]
	\item Points importants
	\item[]
	\item Algorithme CART
		\begin{itemize}
			\item Expansion
			\item \'Elagage
		\end{itemize}
	\item[]
	\item Conclusion
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Arbres de décision}
\begin{itemize}
	\item Classification supervisée
		\begin{itemize}
			\item Classe d'affection $z_i$ connue pour chaque individu $x_i$
			\item Apprendre $f$ qui réduit au maximum l'erreur dans $z_i = f(x_i) + \epsilon$
			\item Similaire à la régression, mais variable à expliquer qualitative
			\item Réutilisation de $f$ sur de nouveaux individus
		\end{itemize}
	\item[]
	\item Statistiques (ex : CART, CHAID)
	\item Apprentissage, Intelligence Artificielle (ex : ID3, C4.5)
	\item[]
	\item Résultats facilement interprétables, exploitables et réutilisables
	\item[]
	\item Règle de décision : \textbf{SI \emph{condition} ALORS \emph{décision}}
	\item Condition sur un ensemble de variables
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple d'arbre de décision}
\centerline{\includegraphics[width=10cm,height=6.5cm]{exemple.pdf}}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Construction de l'arbre}
\begin{itemize}
	\item Description d'un arbre de décision
		\begin{itemize}
			\item N\oe ud de départ comprenant tous les individus, appelé \emph{racine}
			\item N\oe ud intermédiaire (ou \emph{n\oe ud de décision}) correspondant à une partie de la population
			\item Division des n\oe uds en deux \emph{fils} (ou plus selon la méthode), selon un critère sur une variable
			\item N\oe ud terminal appelé \emph{feuille}
			\item Classement d'un individu selon le parcours dans l'arbre correspondant à ses données
		\end{itemize}
	\item[]
	\item Deux phases dans la construction
		\begin{enumerate}
			\item Expansion : Obtention d'un arbre avec des feuilles le plus pur possible
			\item \'Elagage : Simplification de l'arbre dans un but de généralisation
		\end{enumerate}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Idée générale}
\begin{itemize}
	\item Diviser récursivement et le plus efficacement possible chaque n\oe ud
	\item[]
	\item Trois opérateurs important
		\begin{itemize}
			\item Décider si un n\oe ud est terminal ou non
				\begin{itemize}
					\item Tous les individus dans une même classe
					\item Erreur d'affectation raisonnable
				\end{itemize}
			\item Sélectionner une division à un n\oe ud (donc un test)
				\begin{itemize}
					\item Aléatoirement
					\item Critères statistiques
					\item Critères IA
				\end{itemize}
			\item Affecter une classe à une feuille
				\begin{itemize}
					\item Classe majoritaire
					\item Prise en compte du coût ou du risque d'erreur
				\end{itemize}
		\end{itemize}
	\item[]
	\item Critère de sélection de variable à utiliser
	\item Critère de discrimination à partir d'une variable
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Points importants}
\begin{itemize}
	\item Qualité de l'arbre jugé sur l'erreur de classification globale sur les données d'apprentissage
	\item[]
	\item Attention au sur-apprentissage (méfions-nous du \emph{par c\oe ur})
	\item[]
	\item \'Elagage de l'arbre
		\begin{itemize}
			\item Suppression des branches peu représentatives et trop spécifiques
			\item Amélioration des performances de généralisation des règles
			\item Critère d'élagage à définir
		\end{itemize}
	\item[]
	\item Règle de décision produite pour chaque feuille
		\centerline{SI \emph{i $\in$ feuille} ALORS \emph{$z_i$ = classe de la feuille}}
	\item[]
	\item \emph{Support} : nombre d'individus vérifiant la condition
	\item \emph{Confiance} : pourcentage d'invidus vérifant la conclusion
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Notation}
\begin{center}
	\begin{tabular}{lp{7cm}}
	$t$      & arbre \\
	$p$      & position (ou n\oe ud) \\
	$pj$     & fils de $p$ correspondant à la $j$ème branche \\
	$k$      & classe (modalité de la variable cible)\\
	$N(p)$   & Cardinal de l'ensemble des exemples associé à $p$\\
	$N(k/p)$ & Cardinal de l'ensemble des exemples associé à $p$ qui sont de classe $k$\\
	$P(k/p)$ & Proportion d'éléments de classe $k$ à la position $p$\\ % = N(k/p)/N(p)
	\end{tabular}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Préliminaire}
\begin{itemize}
	\item Définition
		\begin{eqnarray}
		  Entropie(p) &=& -\sum_{k=1}^s P(k/p) \times log(P(k/p)) \\
			Gini(p) 	  &=& 1 - \sum_{k=1}^s P(k/p)^2 \nonumber \\
				  	      &=& 2 \sum_{k < k'} P(k/p)P(k'/p) \nonumber \\
			Gain(p,test)&=& i(p) - \sum_{j=1}^n P_{pj} \times i(pj) \label{eq:gain}
	  \end{eqnarray}
	 \item Choix de l'entropie pour $i$
	 \item Gain représentant la différence entre l'entropie du n\oe ud père et les entropies des n\oe uds fils
	 \item Recherche à chaque n\oe ud du test maximisant le gain
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Algorithme CART -- expansion}
\begin{itemize}
	\item \'Echantillon découpé en deux ensembles (apprentissage $A$ pour expansion et test $T$ pour élagage)
	\item Utilisation de la fonction de Gini (ou indice d'impureté de Gini)
	\item[]
	\item Décider si un noeud est terminal 
		\begin{itemize}
			\item $Gini(p) \leq i_0$ ou $N(p) \leq n_0$
			\item $i_0$ et $n_0$ paramètres à fixer
		\end{itemize}
	\item[]
	\item Sélectionner un test à un n\oe ud $p$
		\begin{itemize}
			\item $p1$ et $p2$ fils de $p$
			\item $Gain(p,test) = Gini(p) - (P_{p1} \times Gini(p1) + P_{p2} \times Gini(p2))$
			\item Choix de l'indice de Gini pour $i$ dans l'équation \ref{eq:gain}
		\end{itemize}
	\item[]
	\item Affecter une classe à une feuille
		\begin{itemize}
			\item Classe majoritaire
		\end{itemize}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Algorithme CART -- élagage}
\begin{itemize}
	\item Utilisation de l'ensemble de test $T$ pour l'élagage
	\item[]
	\item Construction de la suite des arbres $t = t_0, \ldots, t_p$
		\begin{itemize}\footnotesize
			\item $t_0$ : arbre obtenu à la fin de la phase d'expansion
			\item $t_r$ : arbre réduit à une feuille
			\item $t_{i+1}$ : arbre élagué de $t_i$
		\end{itemize}
	\item[]
	\item Construction de $t_{i+1}$ à partir de $t_i$
		\begin{itemize}\footnotesize
			\item $\forall p$ de $t_i$, $u_p$ : sous-arbre de $t_i$ avec racine = $p$
			\item Calcul de $g(p) = \frac{\Delta_{app}(p)}{|u_p|-1}$ avec $\Delta_{app}(p) = \frac{MC(p) - MC(u_p)}{N(p)}$
			\item $\Delta_{app}(p)$ : variation d'erreur apparente sur $A$ avec $t$ élagué en $p$
			\item $MC(p)$ et $MC(u_p)$ : nombre de mal-classés de $A$ en $p$ et par $u_p$ resp.
			\item Choix de $p$ pour lequel $g(p)$ est minimal
			\item $t_{i+1}$ : élagué de $t_i$ en $p = arg max_q g(q)$
		\end{itemize}
	\item[]
	\item Choix final 
		\begin{itemize}\footnotesize
			\item Calcul de l'erreur apparente sur $T$ pour chaque arbre $t_i$
			\item Arbre avec l'erreur apparente minimale (estimation de l'erreur réelle)
		\end{itemize}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Algorithme CHAID}
\begin{itemize}
	\item CHisquard Automatic Interaction Detection
	\item[]
	\item Utilisation du $\chi^2$ ou du Tschuprow pour décider de la variable discriminante à chaque n\oe ud
	$$ \chi^2 = \sum_{i=1}^p \sum_{j=1}^d \frac{(f_{ij} - f{i.}f_{.j})^2}{f_{i.}f_{.j}} $$
	$$ T = \sqrt{\frac{\chi^2}{n \sqrt{(p-1)(d-1)}}} $$
	\item[]
	\item Pas de phase d'\'elagage : Limitation de la taille de l'arborescence
	\item[]
	\item Fusion des n\oe uds fils ayant une distribution similaire
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Conclusion}
\begin{itemize}
	\item Plusieurs m\'ethodes existent (CART, ID3, C4.5, C5.0, CHAID, \ldots)
	\item[]
	\item R\'esultats (tr\`es) bons et exploitables dans la pratique
		\begin{itemize}
			\item Compr\'ehensible par tout utilisateur
			\item Traduction en terme de r\`egles de d\'ecision
		\end{itemize}
	\item[]
	\item Tr\`es utilis\'e en Fouille de Donn\'ees
	\item[]
	\item Possibilit\'e de pr\'edire aussi des variables quantitatives (arbres de r\'egression)
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Utilisation sous R}
Programme présent dans le fichier \lstinline!exemple.R! dans le répertoire usuel.
\begin{itemize}\scriptsize
	\item Chargement de la librairie \lstinline!rpart!
		\item[] \lstinline!library(rpart)!
	\item[]
%	\item Visualisation de la table de données \cmd{kyphosis} présente directement sous R
%		\item[] \lstinline!kyphosis!
%	\item[]
	\item Création de l'arbre de décision
		\item[] \lstinline!f = rpart(Kyphosis~Age+Number+Start,data=kyphosis)!
	\item[]
	\item Affichage textuel de l'arbre
		\item[] \lstinline!f!
	\item Affichage visuel de l'arbre
		\item[] \lstinline!plot(f, margin=0.05)!
		\item[] \lstinline!text(f, use.n=T)!
	\item[]
	\item Visualisation des détails de la construction de l'arbre
		\item[] \lstinline!printcp(f)!
		\item[] \lstinline!summary(f)!
	\item[]
	\item Choix d'un autre élagage
		\item[] \lstinline!f2 = prune(f, cp=0.15)!
		\item[] \lstinline!plot(f2, margin=0.05)!
		\item[] \lstinline!text(f2, use.n=T)!
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple de modèle simple}
\begin{itemize}
	\item Niveau de salaire (plus ou moins de 50K\$) en fonction du nombre d'heures par semaine
	\tiny
\begin{lstlisting}
node), split, n, loss, yval, (yprob)
      * denotes terminal node

 1) root 48842 11687 less (0.76071823 0.23928177)  
   2) relationship=Not-in-family,Other-relative,Own-child,Unmarried 
   			26795  1748 less (0.93476395 0.06523605)  
     4) capital_gain< 7055.5 26324  1294 less (0.95084334 0.04915666) *
     5) capital_gain>=7055.5 471    17 more (0.03609342 0.96390658) *
   3) relationship=Husband,Wife 22047  9939 less (0.54919037 0.45080963)  
     6) education_num< 12.5 15429  5167 less (0.66511115 0.33488885)  
      12) capital_gain< 5095.5 14671  4423 less (0.69852089 0.30147911) *
      13) capital_gain>=5095.5 758    14 more (0.01846966 0.98153034) *
     7) education_num>=12.5 6618  1846 more (0.27893623 0.72106377) *
\end{lstlisting}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple de modèle simple}
\begin{itemize}
	\item Niveau de salaire (plus ou moins de 50K\$) en fonction du nombre d'heures par semaine
\begin{lstlisting}
Matrice de confusion
     less  more
  1 35278  5717
  2  1877  5970
  
Taux de mal classés
15.55%
\end{lstlisting}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple de modèle simple}
\begin{itemize}
	\item Arbre de classification
\end{itemize}
\begin{center}
\includegraphics[scale=0.35]{adult_rpart_1.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple de modèle simple}
\begin{itemize}
	\item Représentation visuelle de la validation croisée
\end{itemize}
\begin{center}
\includegraphics[scale=0.35,angle=90]{adult_rpart_1_cp.pdf}
\end{center}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Exemple de modèle complet}
\begin{itemize}
	\item Niveau de salaire (plus ou moins de 50K\$) en fonction du nombre d'heures par semaine
\begin{lstlisting}
Matrice de confusion
     less  more
  1 35479  3580
  2  1676  8107
    
Taux de mal classés
10.77%
\end{lstlisting}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Courbe ROC}
\begin{itemize}
	\item Taux de vrai positif vs Taux de faux positif
\end{itemize}
\includegraphics[scale=0.35]{adult_rpart_ROC.pdf}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Courbe Precision/Recall}
\begin{itemize}
	\item Précision (Nb de vrai positifs sur Nb positifs prédits) vs Taux de vrai positif
\end{itemize}
\includegraphics[scale=0.35]{adult_rpart_PrecRec.pdf}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Courbe de \emph{performance}}
\begin{itemize}
	\item Taux de vrai positifs vs Taux de prédictions positives
	\item Pour 40 \% des positifs prédits, on 89.4 \% des positifs
\end{itemize}
\includegraphics[scale=0.35]{adult_rpart_Perf.pdf}
\end{frame}
%--------------------------------------------------------------------- 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Quelle méthode ? Quelle modèle ?}
\begin{frame}
  \tableofcontents[currentsection]
\end{frame}      

%--------------------------------------------------------------------- frame
\begin{frame}[fragile]{Meilleur modèle en régression}
\begin{itemize}
	\item Régression linéaire
		\begin{itemize}
			\item $R^2$ ajusté maximum (sur données d'apprentissage)
			\item Critère $AIC$ minimum
			\item Variables avec $b_i$ significativement différent de 0
		\end{itemize}
	\item[]
	\item CART
		\begin{itemize}
			\item $R^2$ ajusté maximum (sur données d'apprentissage)
			\item Arbre avec un nombre de n\oe uds minimal
			\item \'Elagage optimisé selon l'évolution du paramètre de complexité 
		\end{itemize}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile] {Meilleur modèle en classification}
\begin{itemize}
	\item Régression logistique
		\begin{itemize}
			\item Critère $AIC$ minimum
			\item Pourcentage de mal-classés sur données d'apprentissage minimum
			\item Variables avec $b_i$ significativement différent de 0
		\end{itemize}
	\item[]
	\item CART
		\begin{itemize}
			\item Pourcentage de mal-classés sur données d'apprentissage minimum
			\item Arbre avec un nombre de n\oe uds minimal
			\item \'Elagage optimisé selon l'évolution du paramètre de complexité 
		\end{itemize}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile] {Comparaison de modèles/méthodes}
\begin{itemize}
	\item En prenant toutes les données
		\begin{itemize}
			\item Dans notre cas, CART meilleur que Régression logistique
			\item Est-ce vrai ?
			\item Qu'en-est'il sur un autre jeu de données ?
		\end{itemize}
	\item[]
	\item Utilisation de 3 échantillons
		\begin{itemize}
			\item \emph{Apprentissage}: pour estimer les paramètres des modèles
			\item \emph{Test} : pour choisir le meilleur modèle
			\item \emph{Validation} : pour estimer la performance sur des données futures
		\end{itemize}
	\item[]
	\item Nécessité de faire plusieurs tirages
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile] {Utilisation de plusieurs échantillons}
\begin{itemize}
	\item \'Echantillon Apprentissage $A$
	\item \'Echantillon Test $T$
	\item \'Echantillon Validation $V$
	\item[]
	\item Procédure
		\begin{itemize}
			\item Construire les différents modèles à partir de $A$
				\begin{itemize}
					\item Plusieurs méthodes
					\item Plusieurs modèles pour chaque méthode
				\end{itemize}
			\item Prévoir les valeurs de la variable cible pour l'échantillon $T$ pour chaque modèle
			\item Comparer les résultats avec les \emph{vraies} valeurs dans $T$
			\item[]
			\item Prévoir les valeurs de la variable cible pour l'échantillon $V$ pour chaque modèle afin d'estimer le vrai pouvoir prédictif du modèle choisi
		\end{itemize}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile] {Exemple de sélection de modèle}
\begin{itemize}
	\item Création des trois échantillons $A$, $T$ et $V$
\begin{lstlisting}
                A     T     V
Effectifs   24415 12251 12176
Proportions    50    25    25
\end{lstlisting}
	\item[]
	\item Vérification de la répartition de la variable cible dans les échantillons
\begin{lstlisting}
     less more   less more
A   18557 5858     76   24
T    9324 2927     76   24
V    9274 2902     76   24
\end{lstlisting}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 


%--------------------------------------------------------------------- frame
\begin{frame}[fragile] {Exemple de sélection de modèle}
\begin{itemize}
	\item Régression logistique
\begin{lstlisting}
Sur données d'apprentissage A : 14.7% de mal-classés

         less  more
  FALSE 17291  2330
  TRUE   1266  3528

sur données de test T : 15.4% de mal-classés
        less more
  FALSE 8624 1184
  TRUE   700 1743
\end{lstlisting}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile] {Exemple de sélection de modèle}
\begin{itemize}
	\item Régression logistique
\begin{lstlisting}
Sur données d'apprentissage A : 12.8% de mal-classés

     less  more
  1 17647  2219
  2   910  3639
  
sur données de test T : 14.2% de mal-classés

    less more
  1 8760 1174
  2  564 1753
\end{lstlisting}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile] {Exemple de sélection de modèle}
\begin{itemize}
	\item Comparaison des deux méthodes : courbe ROC
\end{itemize}
\includegraphics[scale=0.35]{adult_comp_ROC.pdf}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile] {Exemple de sélection de modèle}
\begin{itemize}
	\item Comparaison des deux méthodes : courbe Precision/Recall
\end{itemize}
\includegraphics[scale=0.35]{adult_comp_PrecRec.pdf}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile] {Exemple de sélection de modèle}
\begin{itemize}
	\item Comparaison des deux méthodes : courbe Performances
\end{itemize}
\includegraphics[scale=0.35]{adult_comp_Perf.pdf}
\end{frame}
%--------------------------------------------------------------------- 

%--------------------------------------------------------------------- frame
\begin{frame}[fragile] {Exemple de sélection de modèle}
\begin{itemize}
	\item Validation sur l'échantillon $V$
\begin{lstlisting}
Régression logistique : 15.0% de mal classés

        less more
  FALSE 8582 1140
  TRUE   692 1762

Arbre de classification CART : 13.8% de mal-classés
   
    less more
  1 8716 1128
  2  558 1774
\end{lstlisting}
\end{itemize}
\end{frame}
%--------------------------------------------------------------------- 


\end{document}
